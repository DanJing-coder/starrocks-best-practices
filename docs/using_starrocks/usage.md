# 集群使用规范

为了保障 StarRocks 集群的稳定性、性能和多租户环境下的公平性，所有用户都应遵循本章提出的使用规范。这些规范涵盖了数据导入、查询编写和日常操作等多个方面，旨在帮助您更高效、更安全地使用 StarRocks。

## 1. 数据导入规范

不合理的导入策略是导致集群性能问题（尤其是 Compaction 压力过大）的最常见原因。

### 1.1 避免高频小批量导入

*   **核心原则:** **“合并批次，降低频率”**。
*   **主键模型:** 严禁进行毫秒级的持续导入。高频写入会产生大量的小版本文件，给后台 Compaction 带来巨大压力，导致 CPU 和 I/O 飙升。
    *   **推荐实践:** 在上游（如 Flink）进行微批处理，将导入频率控制在**秒级**（例如 3-5 秒一次），并确保每个批次有一定的数据量（如数万行）。
*   **Stream Load:** 避免将一个大文件拆分成成百上千个小的 Stream Load 任务。应尽可能将数据合并后，通过一次 Stream Load 任务导入。

### 1.2 使用唯一的导入标签 (Label)

*   **核心原则:** 为每一个导入任务都生成一个唯一的、有意义的 `Label`。
*   **作用:**
    *   **幂等性保证:** StarRocks 通过 Label 来防止数据重复导入。使用相同的 Label 重复提交任务，只有第一次会成功。
    *   **问题排查:** 出现导入问题时，可以通过 `SHOW LOAD WHERE LABEL = '...'` 快速定位到具体的任务并查看错误信息。
*   **推荐实践:** Label 可以设计为 `业务名_表名_时间戳` 的格式，例如 `my_app_orders_20231122180000`。

### 1.3 关注数据质量

*   **核心原则:** 尽可能在数据源头或 ETL 阶段保证数据质量。
*   **`max_filter_ratio`:** 这个参数允许导入一定比例的“脏数据”（格式错误、类型不匹配等）。虽然方便，但过度依赖会导致性能下降，因为 BE 需要花费额外资源来处理错误。
*   **推荐实践:** 生产环境的 `max_filter_ratio` 建议设置为 `0`。当出现导入错误时，应根据错误日志 (`ErrorURL`) 定位并清洗源头数据，而不是简单地调大过滤比例。

## 2. 查询规范

不规范的 SQL 写法是导致查询缓慢、消耗过多集群资源的主要原因。

### 2.1 明确指定查询列

*   **核心原则:** **严禁使用 `SELECT *`**。
*   **原因:**
    *   StarRocks 是列式存储，只读取需要的列可以极大地减少 I/O。
    *   `SELECT *` 会读取所有列的数据，即使你只使用其中几列，这会造成巨大的资源浪费。
*   **推荐实践:** 在 `SELECT` 子句中明确列出所有需要查询的字段。

### 2.2 高效使用过滤条件

*   **核心原则:** **“尽早过滤，精准过滤”**。
*   **分区裁剪:** 查询时应尽可能地在 `WHERE` 子句中带上分区键（通常是时间字段）的过滤条件，以便 StarRocks 能够只扫描相关的分区，跳过大量无关数据。
    *   **反例:** `WHERE substring(event_time, 1, 10) = '2023-11-22'` (无法利用分区)
    *   **正例:** `WHERE event_time >= '2023-11-22 00:00:00' AND event_time < '2023-11-23 00:00:00'` (高效利用分区)
*   **排序键前缀过滤:** 将高频过滤字段设计为排序键，并在查询时使用它们，可以利用前缀索引快速定位数据。
*   **避免在列上使用函数:** 在 `WHERE` 子句中对列使用函数会导致索引失效。
    *   **反例:** `WHERE year(create_time) = 2023`
    *   **正例:** `WHERE create_time >= '2023-01-01' AND create_time < '2024-01-01'`

### 2.3 小心处理大数据量 Join

*   **核心原则:** 理解 Join 的代价，避免笛卡尔积。
*   **Join 条件:** 确保 `ON` 子句中的 Join 条件是正确且高效的。检查 Join 列的数据类型是否一致，避免隐式类型转换带来的开销。
*   **大表 Join 大表:** 两个超大表的 Join 会消耗巨大的内存和 CPU 资源，是性能杀手。
    *   **推荐实践:**
        1.  **业务逻辑优化:** 思考是否真的需要全量 Join，能否通过增加过滤条件来减少参与 Join 的数据量。
        2.  **数据模型优化:** 考虑是否可以将部分数据预先处理成一张宽表，或者使用物化视图来预计算 Join 结果。
        3.  **Colocate Join:** 如果多个大表都使用相同的分桶键，可以启用 Colocate Join，避免数据在节点间重分布（Shuffle），极大提升 Join 性能。

### 2.4 使用 `EXPLAIN` 分析执行计划

*   **核心原则:** 对于任何不符合预期的慢查询，第一步都应该是 `EXPLAIN`。
*   **作用:** `EXPLAIN` 可以展示查询的逻辑计划和物理计划，帮助你理解 StarRocks 是如何执行你的 SQL 的。
*   **关注点:**
    *   **`scan` 算子:** 查看 `predicates` 是否被成功下推，`partitions` 是否被有效裁剪。
    *   **`join` 算子:** 查看 Join 类型（如 `HASH_JOIN`, `BROADCAST_JOIN`）和数据交换方式（`SHUFFLE`, `BROADCAST`）。
    *   **估算行数:** 检查优化器估算的行数与实际行数是否有巨大偏差，这可能意味着统计信息过时。

### 2.5 小心使用 UPDATE 和 DELETE

StarRocks 的主键模型支持 `UPDATE` 和 `DELETE` 操作，但这两种操作在 OLAP 环境中是昂贵的，应谨慎使用。

*   **适用模型:** `UPDATE` 和 `DELETE` 仅对**主键模型**生效。
*   **性能开销:**
    *   其底层实现为“先标记删除，再插入新行”(Delete-and-Insert)，会产生新的数据版本并增加 Compaction 压力。
    *   **不适用于高频的事务性更新**。对于需要频繁更新的场景，应优先考虑通过 Flink CDC 等方式进行流式写入。
*   **使用规范:**
    *   **必须带 WHERE 条件:** 为防止误操作，`DELETE` 和 `UPDATE` 语句都必须包含 `WHERE` 子句。
    *   **过滤条件尽量命中主键:** `WHERE` 条件如果能过滤主键，执行效率最高。如果过滤非主键列，可能会导致大范围的数据扫描，性能较差。
    *   **批量操作:** 尽量将多个小范围的更新或删除合并成一个批次执行，以减少事务开销和版本数量。
    *   **适用场景:**
        *   **数据订正:** 用于修正少量的错误数据。
        *   **低频更新:** 用于更新少量维度信息或状态。
        *   对于大规模的数据变更，推荐使用 `INSERT OVERWRITE` 或重新导入数据的方式。

## 3. 日常操作规范

*   **DDL 操作:**
    *   `ADD COLUMN` 等操作是异步的，可以通过 `SHOW ALTER TABLE COLUMN` 查看进度。
    *   避免在业务高峰期执行耗时较长的 DDL 操作。
*   **用户与权限:**
    *   遵循最小权限原则，为不同的业务角色创建不同的用户，并授予其所需的最小权限集。
    *   不建议在生产环境中使用 `root` 账号进行日常查询和开发。
*   **会话变量:**
    *   对于临时的大查询，应在当前会话中使用 `SET` 命令来调整参数（如 `SET exec_mem_limit = ...`），而不是修改全局配置，避免影响其他用户。